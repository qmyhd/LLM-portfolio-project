{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c717ea36",
   "metadata": {},
   "source": [
    "# Discord Data Cleaning and Processing\n",
    "\n",
    "This notebook processes raw Discord messages, extracting ticker symbols, performing sentiment analysis, and preparing the data for use in portfolio analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8989cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, textwrap\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from datetime import datetime\n",
    "import ast\n",
    "import json\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "from pathlib import Path\n",
    "#install textblob if not already installed\n",
    "from textblob import TextBlob #pip install textblob\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "RAW  = Path('../data/raw/discord_msgs.csv')\n",
    "OUT  = Path('../data/processed/discord_msgs_clean.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e56fe06",
   "metadata": {},
   "source": [
    "## Data Cleaning Process\n",
    "\n",
    "We'll perform the following steps:\n",
    "1. Load raw Discord messages and normalize timestamps\n",
    "2. Apply feature engineering to extract useful information\n",
    "3. Perform sentiment analysis using TextBlob\n",
    "4. Save the cleaned data in an efficient format (Parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d280224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ cleaned file saved → ..\\data\\processed\\discord_msgs_clean.parquet\n",
      "   rows: 119   cols: 11\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------ #\n",
    "# 1. LOAD & BASIC NORMALISATION\n",
    "df = pd.read_csv(RAW)\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], utc=True)\n",
    "df = df.sort_values('created_at')              # chronological\n",
    "df = df.drop_duplicates('message_id')          # safety\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 2. LIGHT FEATURE ENGINEERING\n",
    "df['char_len']   = df['content'].str.len()\n",
    "df['word_len']   = df['content'].str.split().str.len()\n",
    "\n",
    "# Tickers → list ( [] if NaN )\n",
    "df['tickers'] = (df['tickers_detected']\n",
    "                   .fillna('')\n",
    "                   .apply(lambda s: re.findall(r'\\$[A-Z]{2,6}', s)))\n",
    "\n",
    "# Tweet URLs → list\n",
    "df['tweet_urls'] = (df['tweet_urls']\n",
    "                      .fillna('')\n",
    "                      .str.split(',\\s*') )\n",
    "\n",
    "# Basic sentiment   (polarity ∈ [-1,1])\n",
    "df['sentiment'] = df['content'].apply(\n",
    "    lambda t: TextBlob(str(t)).sentiment.polarity\n",
    ")\n",
    "\n",
    "# Command flag (e.g. “!history”)\n",
    "df['is_command'] = df['content'].str.startswith('!')\n",
    "\n",
    "# Keep only useful columns\n",
    "keep = ['message_id','created_at','channel','author_name',\n",
    "        'content','tickers','tweet_urls',\n",
    "        'char_len','word_len','sentiment','is_command']\n",
    "df = df[keep]\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 3. SAVE TIDY VERSION\n",
    "df.to_parquet(OUT, index=False)\n",
    "print(f'✅ cleaned file saved → {OUT}\\n'\n",
    "      f'   rows: {len(df):,}   cols: {len(df.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e24cca",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's examine a sample of our processed data to verify the cleaning steps worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaceaab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data and display a sample\n",
    "clean_df = pd.read_parquet(OUT)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17bfb44",
   "metadata": {},
   "source": [
    "## Ticker Symbol Analysis\n",
    "\n",
    "Let's analyze the most frequently mentioned ticker symbols in our Discord data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c8e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all ticker mentions\n",
    "all_tickers = [ticker for tickers_list in clean_df['tickers'] for ticker in tickers_list if tickers_list]\n",
    "\n",
    "# Count occurrences\n",
    "ticker_counts = pd.Series(all_tickers).value_counts().reset_index()\n",
    "ticker_counts.columns = ['ticker', 'mentions']\n",
    "\n",
    "# Display top 10 tickers\n",
    "ticker_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05b5b09",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Let's visualize the sentiment distribution for messages mentioning ticker symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc1e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for messages with tickers\n",
    "msgs_with_tickers = clean_df[clean_df['tickers'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Plot sentiment distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(msgs_with_tickers['sentiment'], bins=20, kde=True)\n",
    "plt.title('Sentiment Distribution for Stock-Related Messages')\n",
    "plt.xlabel('Sentiment Score (-1 to 1)')\n",
    "plt.ylabel('Count')\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
